{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49e77070-bd03-410f-87a1-8a61c09de907",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import DenseNet121\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e28a1e6f-b32f-47dc-8925-f29a19ec72cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "data_dir = '/home/sivaranjin/lost+found/Speech/Urban Scene/Database/Database'  # Replace with your data directory\n",
    "batch_size = 64\n",
    "img_height, img_width = 224, 224\n",
    "num_classes = 4\n",
    "learning_rate = 0.0001\n",
    "num_epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4262e9d-659c-4eab-8ce0-5ca4bb6864b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data generators with data augmentation\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1.0/255,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "val_datagen = ImageDataGenerator(rescale=1.0/255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c140a203-abf3-4f95-b8ba-6ac512a0ad09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data from directory\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    directory=f'{data_dir}/train',\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    seed=42,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "\n",
    "val_generator = val_datagen.flow_from_directory(\n",
    "    f'{data_dir}/val',\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd25e34e-aab2-45fd-bc3e-bc82bf6b7d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute class weights for imbalanced dataset\n",
    "y_train = train_generator.classes\n",
    "class_weights = compute_class_weight(\n",
    "    class_weight='balanced',\n",
    "    classes=np.unique(y_train),\n",
    "    y=y_train\n",
    ")\n",
    "class_weights = dict(enumerate(class_weights))\n",
    "\n",
    "print(\"Class weights:\", class_weights)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35387eab-9e60-4295-b1c5-007ddb3c85fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Model 01\n",
    "\n",
    "# import tensorflow as tf\n",
    "# from tensorflow.keras.layers import (\n",
    "#     Conv2D, DepthwiseConv2D, SeparableConv2D, MaxPooling2D, GlobalAveragePooling2D, \n",
    "#     Dense, Dropout, BatchNormalization, ReLU, Input\n",
    "# )\n",
    "# from tensorflow.keras.models import Model\n",
    "\n",
    "# def create_custom_cnn(input_shape=(224, 224, 3), num_classes=4):\n",
    "#     inputs = Input(shape=input_shape)\n",
    "    \n",
    "#     # Convolutional Block 1\n",
    "#     x = Conv2D(64, (3, 3), padding=\"same\", activation=None)(inputs)\n",
    "#     x = BatchNormalization()(x)\n",
    "#     x = ReLU()(x)\n",
    "#     x = MaxPooling2D((2, 2))(x)\n",
    "    \n",
    "#     # Convolutional Block 2\n",
    "#     x = Conv2D(128, (3, 3), padding=\"same\", activation=None)(x)\n",
    "#     x = BatchNormalization()(x)\n",
    "#     x = ReLU()(x)\n",
    "#     x = MaxPooling2D((2, 2))(x)\n",
    "    \n",
    "#     # Convolutional Block 3\n",
    "#     x = SeparableConv2D(256, (3, 3), padding=\"same\", activation=None)(x)\n",
    "#     x = BatchNormalization()(x)\n",
    "#     x = ReLU()(x)\n",
    "#     x = MaxPooling2D((2, 2))(x)\n",
    "    \n",
    "#     # Convolutional Block 4\n",
    "#     x = SeparableConv2D(512, (3, 3), padding=\"same\", activation=None)(x)\n",
    "#     x = BatchNormalization()(x)\n",
    "#     x = ReLU()(x)\n",
    "#     x = GlobalAveragePooling2D()(x)\n",
    "    \n",
    "#     # Dense Layer\n",
    "#     x = Dense(256, activation=\"relu\")(x)\n",
    "#     x = Dropout(0.4)(x)\n",
    "    \n",
    "#     # Output Layer\n",
    "#     outputs = Dense(num_classes, activation=\"softmax\")(x)\n",
    "    \n",
    "#     # Model definition\n",
    "#     model = Model(inputs, outputs)\n",
    "#     return model\n",
    "\n",
    "# # Instantiate the model\n",
    "# model = create_custom_cnn()\n",
    "\n",
    "# # Compile the model\n",
    "# model.compile(\n",
    "#     optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),\n",
    "#     loss=\"categorical_crossentropy\",\n",
    "#     metrics=[\"accuracy\"]\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39b467e5-1c3a-4695-89cb-8479cb43c4f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Model 02\n",
    "# import tensorflow as tf\n",
    "# from tensorflow.keras.layers import (\n",
    "#     Conv2D, DepthwiseConv2D, SeparableConv2D, Dense, BatchNormalization, \n",
    "#     ReLU, GlobalAveragePooling2D, Add, Dropout, Input, AveragePooling2D\n",
    "# )\n",
    "# from tensorflow.keras.models import Model\n",
    "\n",
    "# def squeeze_and_excite_block(inputs, ratio=16):\n",
    "#     filters = inputs.shape[-1]\n",
    "#     se = GlobalAveragePooling2D()(inputs)\n",
    "#     se = Dense(filters // ratio, activation=\"relu\")(se)\n",
    "#     se = Dense(filters, activation=\"sigmoid\")(se)\n",
    "#     return tf.keras.layers.Multiply()([inputs, se])\n",
    "\n",
    "# def dense_residual_block(x, growth_rate, use_se=False):\n",
    "#     # Bottleneck layer\n",
    "#     conv1 = Conv2D(growth_rate, (1, 1), padding=\"same\", activation=None)(x)\n",
    "#     conv1 = BatchNormalization()(conv1)\n",
    "#     conv1 = ReLU()(conv1)\n",
    "    \n",
    "#     # Depthwise separable convolution\n",
    "#     conv2 = SeparableConv2D(growth_rate, (3, 3), padding=\"same\", activation=None)(conv1)\n",
    "#     conv2 = BatchNormalization()(conv2)\n",
    "#     conv2 = ReLU()(conv2)\n",
    "    \n",
    "#     # Attention block\n",
    "#     if use_se:\n",
    "#         conv2 = squeeze_and_excite_block(conv2)\n",
    "    \n",
    "#     # Concatenate input and output for dense connections\n",
    "#     return tf.keras.layers.Concatenate()([x, conv2])\n",
    "\n",
    "# def create_hybrid_cnn(input_shape=(224, 224, 3), num_classes=4):\n",
    "#     inputs = Input(shape=input_shape)\n",
    "    \n",
    "#     # Stem Block\n",
    "#     x = SeparableConv2D(32, (3, 3), strides=(2, 2), padding=\"same\")(inputs)\n",
    "#     x = BatchNormalization()(x)\n",
    "#     x = ReLU()(x)\n",
    "    \n",
    "#     # Dense Residual Blocks\n",
    "#     for _ in range(3):  # Add 3 dense residual blocks\n",
    "#         x = dense_residual_block(x, growth_rate=64, use_se=True)\n",
    "#         x = AveragePooling2D((2, 2))(x)  # Transition layer\n",
    "    \n",
    "#     # Global Average Pooling\n",
    "#     x = GlobalAveragePooling2D()(x)\n",
    "    \n",
    "#     # Fully Connected Layer\n",
    "#     x = Dense(256, activation=\"relu\")(x)\n",
    "#     x = Dropout(0.4)(x)\n",
    "    \n",
    "#     # Output Layer\n",
    "#     outputs = Dense(num_classes, activation=\"softmax\")(x)\n",
    "    \n",
    "#     # Create Model\n",
    "#     model = Model(inputs, outputs)\n",
    "#     return model\n",
    "\n",
    "# # Instantiate the model\n",
    "# model = create_hybrid_cnn()\n",
    "\n",
    "# # Compile the model\n",
    "# model.compile(\n",
    "#     optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),\n",
    "#     loss=\"categorical_crossentropy\",\n",
    "#     metrics=[\"accuracy\"]\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7db47507-d238-41d5-bf28-67b53004a638",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Model 03\n",
    "\n",
    "# import tensorflow as tf\n",
    "# from tensorflow.keras.layers import (\n",
    "#     Input, Conv2D, DepthwiseConv2D, SeparableConv2D, BatchNormalization, ReLU, \n",
    "#     Add, Concatenate, GlobalAveragePooling2D, Dense, Dropout, AveragePooling2D\n",
    "# )\n",
    "# from tensorflow.keras.models import Model\n",
    "\n",
    "# def squeeze_and_excite(inputs, reduction_ratio=16):\n",
    "#     \"\"\"Squeeze-and-Excitation block for lightweight attention.\"\"\"\n",
    "#     filters = inputs.shape[-1]\n",
    "#     se = GlobalAveragePooling2D()(inputs)\n",
    "#     se = Dense(filters // reduction_ratio, activation=\"relu\")(se)\n",
    "#     se = Dense(filters, activation=\"sigmoid\")(se)\n",
    "#     return tf.keras.layers.Multiply()([inputs, se])\n",
    "\n",
    "# def dense_residual_block(inputs, filters, use_attention=True):\n",
    "#     \"\"\"Dense Residual Block combining DenseNet and ResNet features.\"\"\"\n",
    "#     # Bottleneck Convolution\n",
    "#     x = BatchNormalization()(inputs)\n",
    "#     x = ReLU()(x)\n",
    "#     x = Conv2D(filters, (1, 1), padding=\"same\", use_bias=False)(x)\n",
    "\n",
    "#     # Depthwise Separable Convolution\n",
    "#     x = BatchNormalization()(x)\n",
    "#     x = ReLU()(x)\n",
    "#     x = SeparableConv2D(filters, (3, 3), padding=\"same\", use_bias=False)(x)\n",
    "    \n",
    "#     # Attention Mechanism\n",
    "#     if use_attention:\n",
    "#         x = squeeze_and_excite(x)\n",
    "    \n",
    "#     # Align input shape with output shape\n",
    "#     if inputs.shape[-1] != filters:\n",
    "#         inputs = Conv2D(filters, (1, 1), padding=\"same\", use_bias=False)(inputs)\n",
    "    \n",
    "#     # Add residual connection\n",
    "#     return Add()([inputs, x])\n",
    "\n",
    "\n",
    "# def create_hybrid_cnn(input_shape=(224, 224, 3), num_classes=4):\n",
    "#     inputs = Input(shape=input_shape)\n",
    "\n",
    "#     # Stem Block: Initial feature extraction\n",
    "#     x = Conv2D(32, (3, 3), strides=(2, 2), padding=\"same\", use_bias=False)(inputs)\n",
    "#     x = BatchNormalization()(x)\n",
    "#     x = ReLU()(x)\n",
    "    \n",
    "#     x = DepthwiseConv2D((3, 3), strides=(1, 1), padding=\"same\", use_bias=False)(x)\n",
    "#     x = BatchNormalization()(x)\n",
    "#     x = ReLU()(x)\n",
    "    \n",
    "#     # Dense Residual Blocks\n",
    "#     for filters in [64, 128, 256]:  # Incrementing filters\n",
    "#         x = dense_residual_block(x, filters)\n",
    "#         x = AveragePooling2D((2, 2))(x)  # Transition layer\n",
    "\n",
    "#     # Final Convolution Block\n",
    "#     x = Conv2D(512, (1, 1), padding=\"same\", use_bias=False)(x)\n",
    "#     x = BatchNormalization()(x)\n",
    "#     x = ReLU()(x)\n",
    "    \n",
    "#     # Global Average Pooling\n",
    "#     x = GlobalAveragePooling2D()(x)\n",
    "\n",
    "#     # Fully Connected Layer\n",
    "#     x = Dense(256, activation=\"relu\")(x)\n",
    "#     x = Dropout(0.4)(x)\n",
    "\n",
    "#     # Output Layer\n",
    "#     outputs = Dense(num_classes, activation=\"softmax\")(x)\n",
    "\n",
    "#     # Create Model\n",
    "#     model = Model(inputs, outputs)\n",
    "#     return model\n",
    "\n",
    "# # Instantiate the model\n",
    "# model = create_hybrid_cnn()\n",
    "\n",
    "# # Compile the model\n",
    "# model.compile(\n",
    "#     optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "#     loss=\"categorical_crossentropy\",\n",
    "#     metrics=[\"accuracy\"]\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bfc171b-2bf3-4e34-b789-4ff7d2eba942",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Model 04\n",
    "\n",
    "# import tensorflow as tf\n",
    "# from tensorflow.keras.layers import (\n",
    "#     Input, Conv2D, DepthwiseConv2D, SeparableConv2D, BatchNormalization, ReLU, \n",
    "#     Add, GlobalAveragePooling2D, Dense, Dropout, AveragePooling2D, Concatenate\n",
    "# )\n",
    "# from tensorflow.keras.models import Model\n",
    "\n",
    "# def squeeze_and_excite(inputs, reduction_ratio=16):\n",
    "#     \"\"\"Squeeze-and-Excitation block.\"\"\"\n",
    "#     filters = inputs.shape[-1]\n",
    "#     se = tf.keras.layers.GlobalAveragePooling2D()(inputs)\n",
    "#     se = Dense(filters // reduction_ratio, activation=\"relu\")(se)\n",
    "#     se = Dense(filters, activation=\"sigmoid\")(se)\n",
    "#     return tf.keras.layers.Multiply()([inputs, se])\n",
    "\n",
    "# def dense_residual_block(inputs, filters, use_attention=True):\n",
    "#     \"\"\"Dense Residual Block with attention.\"\"\"\n",
    "#     x = BatchNormalization()(inputs)\n",
    "#     x = ReLU()(x)\n",
    "#     x = Conv2D(filters, (1, 1), padding=\"same\", use_bias=False)(x)\n",
    "\n",
    "#     x = BatchNormalization()(x)\n",
    "#     x = ReLU()(x)\n",
    "#     x = SeparableConv2D(filters, (3, 3), padding=\"same\", use_bias=False)(x)\n",
    "    \n",
    "#     if use_attention:\n",
    "#         x = squeeze_and_excite(x)\n",
    "\n",
    "#     if inputs.shape[-1] != filters:\n",
    "#         inputs = Conv2D(filters, (1, 1), padding=\"same\", use_bias=False)(inputs)\n",
    "    \n",
    "#     return Add()([inputs, x])\n",
    "\n",
    "# def multi_scale_feature_fusion(inputs):\n",
    "#     \"\"\"Fuse features at multiple scales.\"\"\"\n",
    "#     x1 = Conv2D(inputs.shape[-1] // 2, (1, 1), padding=\"same\")(inputs)\n",
    "#     x2 = Conv2D(inputs.shape[-1] // 2, (3, 3), padding=\"same\")(inputs)\n",
    "#     x3 = Conv2D(inputs.shape[-1] // 2, (5, 5), padding=\"same\")(inputs)\n",
    "#     return Concatenate()([x1, x2, x3])\n",
    "\n",
    "# def create_hybrid_cnn(input_shape=(224, 224, 3), num_classes=4):\n",
    "#     inputs = Input(shape=input_shape)\n",
    "\n",
    "#     # Stem Block\n",
    "#     x = Conv2D(32, (3, 3), strides=(2, 2), padding=\"same\", use_bias=False)(inputs)\n",
    "#     x = BatchNormalization()(x)\n",
    "#     x = ReLU()(x)\n",
    "\n",
    "#     # Multi-Scale Feature Fusion\n",
    "#     x = multi_scale_feature_fusion(x)\n",
    "\n",
    "#     # Dense Residual Blocks\n",
    "#     for filters in [64, 128, 256]:\n",
    "#         x = dense_residual_block(x, filters)\n",
    "#         x = AveragePooling2D((2, 2))(x)\n",
    "\n",
    "#     # Final Convolution Block\n",
    "#     x = Conv2D(512, (1, 1), padding=\"same\", use_bias=False)(x)\n",
    "#     x = BatchNormalization()(x)\n",
    "#     x = ReLU()(x)\n",
    "\n",
    "#     # Global Average Pooling\n",
    "#     x = GlobalAveragePooling2D()(x)\n",
    "\n",
    "#     # Fully Connected Layers\n",
    "#     x = Dense(256, activation=\"relu\")(x)\n",
    "#     x = Dropout(0.4)(x)\n",
    "#     outputs = Dense(num_classes, activation=\"softmax\")(x)\n",
    "\n",
    "#     model = Model(inputs, outputs)\n",
    "#     return model\n",
    "\n",
    "# # Instantiate the model\n",
    "# model = create_hybrid_cnn()\n",
    "\n",
    "# # Compile the model\n",
    "# model.compile(\n",
    "#     optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "#     loss=\"categorical_crossentropy\",\n",
    "#     metrics=[\"accuracy\"]\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b4a3d6e-8c77-44a4-8ca0-f4fa082e14b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import (\n",
    "    Conv2D, SeparableConv2D, MaxPooling2D, GlobalAveragePooling2D, Dense, \n",
    "    Dropout, BatchNormalization, ReLU, Input, Add\n",
    ")\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.regularizers import l2\n",
    "\n",
    "def squeeze_and_excite(x, ratio=16):\n",
    "    \"\"\"Squeeze-and-Excite block to recalibrate the feature maps.\"\"\"\n",
    "    channel_axis = -1\n",
    "    filters = x.shape[channel_axis]\n",
    "    \n",
    "    # Squeeze\n",
    "    se = GlobalAveragePooling2D()(x)\n",
    "    se = Dense(filters // ratio, activation=\"relu\", use_bias=False)(se)\n",
    "    se = Dense(filters, activation=\"sigmoid\", use_bias=False)(se)\n",
    "    \n",
    "    # Scale\n",
    "    se = tf.reshape(se, [-1, 1, 1, filters])\n",
    "    return x * se\n",
    "\n",
    "def residual_block(x, filters, kernel_size=(3, 3), strides=(1, 1), use_se=False):\n",
    "    \"\"\"Residual block with an optional squeeze and excite mechanism.\"\"\"\n",
    "    shortcut = x\n",
    "    \n",
    "    # Apply 1x1 convolution to shortcut to match the output shape\n",
    "    if x.shape[-1] != filters:\n",
    "        shortcut = Conv2D(filters, (1, 1), padding=\"same\", strides=strides, activation=None)(x)\n",
    "        shortcut = BatchNormalization()(shortcut)\n",
    "    \n",
    "    # Convolutional Layers\n",
    "    x = Conv2D(filters, kernel_size, strides=strides, padding=\"same\", activation=None)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = ReLU()(x)\n",
    "    \n",
    "    # Optional Squeeze-and-Excite block\n",
    "    if use_se:\n",
    "        x = squeeze_and_excite(x)\n",
    "    \n",
    "    x = Conv2D(filters, kernel_size, strides=strides, padding=\"same\", activation=None)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    \n",
    "    # Add shortcut\n",
    "    x = Add()([x, shortcut])\n",
    "    x = ReLU()(x)\n",
    "    \n",
    "    return x\n",
    "\n",
    "def create_custom_cnn(input_shape=(224, 224, 3), num_classes=4, learning_rate=1e-4):\n",
    "    inputs = Input(shape=input_shape)\n",
    "    \n",
    "    # Initial Conv Block\n",
    "    x = Conv2D(64, (3, 3), padding=\"same\", activation=None)(inputs)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = ReLU()(x)\n",
    "    x = MaxPooling2D((2, 2))(x)\n",
    "    \n",
    "    # Residual Block 1\n",
    "    x = residual_block(x, 128, use_se=True)\n",
    "    \n",
    "    # Residual Block 2\n",
    "    x = residual_block(x, 256, use_se=True)\n",
    "    \n",
    "    # Separable Conv Block (to reduce the number of parameters)\n",
    "    x = SeparableConv2D(512, (3, 3), padding=\"same\", activation=None)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = ReLU()(x)\n",
    "    x = MaxPooling2D((2, 2))(x)\n",
    "    \n",
    "    # Global Average Pooling\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    \n",
    "    # Dense Layer with L2 Regularization\n",
    "    x = Dense(256, activation=\"relu\", kernel_regularizer=l2(0.01))(x)\n",
    "    x = Dropout(0.4)(x)\n",
    "    \n",
    "    # Output Layer\n",
    "    outputs = Dense(num_classes, activation=\"softmax\")(x)\n",
    "    \n",
    "    # Model definition\n",
    "    model = Model(inputs, outputs)\n",
    "    return model\n",
    "\n",
    "# Instantiate the model\n",
    "model = create_custom_cnn()\n",
    "\n",
    "# Compile the model\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),\n",
    "    loss=\"categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f026b8e5-fb4f-4ff7-9739-e986e5c83251",
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "    tf.keras.callbacks.ModelCheckpoint(\n",
    "        \"custom_model7.h5\", save_best_only=True, monitor=\"val_loss\"\n",
    "    ),\n",
    "tf.keras.callbacks.ReduceLROnPlateau(\n",
    "        monitor=\"val_loss\", factor=0.1, patience=7, min_lr=1e-6\n",
    "    ),\n",
    "    tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=5, verbose=1, restore_best_weights=True),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adc1603d-f83b-45e4-a29b-e76c6ed9afa8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Display model summary to get parameter details\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c106943-e774-4968-b9f3-11955689f7bc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Train the model\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    epochs=num_epochs,\n",
    "    validation_data=val_generator,\n",
    "    class_weight=class_weights,\n",
    "    verbose=1,\n",
    "    callbacks = callbacks\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "294df423-b19e-4c86-b9a1-4111a2ecfe13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot accuracy and loss curves\n",
    "def plot_training_curves(history):\n",
    "    acc = history.history['accuracy']\n",
    "    val_acc = history.history['val_accuracy']\n",
    "    loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "\n",
    "    epochs_range = range(num_epochs)\n",
    "    plt.figure(figsize=(12, 4))\n",
    "\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(acc, label='Train')\n",
    "    plt.plot(val_acc, label='Validation')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.title('Training and Validation Accuracy')\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(loss, label='Train')\n",
    "    plt.plot(val_loss, label='Validation')\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.title('Training and Validation Loss')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "plot_training_curves(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d15a3988-da93-49f2-b8c7-110464453416",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "# Confusion Matrix\n",
    "y_true = val_generator.classes\n",
    "y_pred = np.argmax(model.predict(val_generator), axis=1)\n",
    "\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=train_generator.class_indices.keys())\n",
    "disp.plot(cmap='Blues')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39d7dea3-cc01-4ddf-b273-5c85106ecfd7",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Evaluate the model on validation data\n",
    "loss, accuracy = model.evaluate(val_generator)\n",
    "print(f\"Validation Accuracy: {accuracy*100:.2f}%\")\n",
    "# print(f\"Validation Precision: {precision:.2f}\")\n",
    "# print(f\"Validation Recall: {recall:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab4704a1-7b30-490d-89cc-8b530710c9f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import metrics\n",
    "from pytictoc import TicToc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eca92fb-ae9c-4a5f-b415-ca004ee2912d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTANT\n",
    "# run this cell minimum 2 times to get approximate correct-timing results.\n",
    "\n",
    "t = TicToc()\n",
    "t.tic()\n",
    "y_pred = np.argmax(model.predict(val_generator), axis=1)\n",
    "t.toc('\\nThis testing took')\n",
    "total_time = t.tocvalue('This testing took')\n",
    "total_seg = y_pred.shape[0]\n",
    "\n",
    "print(\"Average testing time is {} milliseconds\\n\".format(total_time*1000/total_seg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf3c08bf-a32d-41fe-9a5b-7d15840c6c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "\n",
    "feature_extractor = Model(inputs=model.input, outputs=model.layers[-2].output)\n",
    "features = feature_extractor.predict(val_generator)\n",
    "labels = val_generator.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1c12b85-adfd-4cd0-ac68-25c8c31b27a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "\n",
    "tsne = TSNE(n_components=3, random_state=0)\n",
    "tsne_results = tsne.fit_transform(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c61da1a7-6f9e-4fba-9056-34e2bf1ebe1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne_results.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8ba1e45-eb2f-4f8a-8d96-728b6e2caaef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(tsne_results, columns=['t-SNE x1', 't-SNE x2', 't-SNE x3'])\n",
    "df['Classes'] = labels\n",
    "\n",
    "fig = px.scatter_3d(df, x='t-SNE x1', y='t-SNE x2', z='t-SNE x3', color='Classes', size_max=5)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ae4c653-ba86-4515-a901-b081e2c7d698",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "# Create a figure\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "# Create scatter plot\n",
    "scatter = ax.scatter(tsne_results[:, 0], tsne_results[:, 1], tsne_results[:, 2], c=labels, cmap='plasma', marker='o', s = 2)\n",
    "\n",
    "# # Add legend\n",
    "# legend1 = ax.legend(['cry', 'non-cry'], loc=\"upper right\",  title=\"Classes\")\n",
    "# ax.add_artist(legend1)\n",
    "\n",
    "# Custom legend\n",
    "class_names = {0: 'Cycle', 1: 'Motorcycle', 2: 'Pedestrians', 3: 'Traffic'}\n",
    "handles, _ = scatter.legend_elements()\n",
    "legend_labels = [class_names[int(label)] for label in np.unique(labels)]\n",
    "legend = ax.legend(handles, legend_labels, loc=\"upper right\")\n",
    "\n",
    "# Set labels\n",
    "ax.set_xlabel('t-SNE x1')\n",
    "ax.set_ylabel('t-SNE x2')\n",
    "ax.set_zlabel('t-SNE x3')\n",
    "\n",
    "# Show plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f0c6bff-9d35-4efb-af38-da32e931b4e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.savefig(\"custom_model7_t-SNE.pdf\") "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
